[build-system]
requires = ["hatchling>=1.24"]
build-backend = "hatchling.build"

[project]
name = "mychatai"
version = "0.1.0"
description = "Unified chat-LLM orchestration layer (OpenAI • Ollama • Claude • Gemini • DeepSeek)"
authors = [{ name = "Your Name", email = "you@example.com" }]
readme = "README.md"
license = { text = "MIT" }
requires-python = ">=3.9"

# ── Core runtime deps (tiny footprint) ─────────────────────────────────────────
dependencies = [
  "openai>=1.28",             # OpenAI + DeepSeek (OpenAI-compatible)
  "httpx>=0.27",
  "pydantic>=2.11",
  "pydantic-settings>=2.1",
  "click>=8.1",
]

[project.optional-dependencies]
dev = [
  "pytest>=8",
  "pytest-mock>=3",
  "ruff",
  "mypy",
]

# UI & additional providers are kept optional
ui = [
  "gradio>=4.31",             # nice UI front-end
  "google-generativeai>=0.6", # official Gemini SDK
  "anthropic>=0.25",          # Claude SDK
]

[project.scripts]
ask   = "scripts.ask:main"
serve = "serve_gradio:demo.launch"     # python -m mychatai serve  OR  serve
